/*
 * This Java source file was generated by the Gradle 'init' task.
 */
package kstreams.playground.app;



import io.confluent.kafka.streams.serdes.avro.SpecificAvroSerde;
import java.time.Duration;
import java.util.Collections;
import java.util.Properties;
import ksql.pageviews;
import kstreams.playground.shared.AppContext;
import kstreams.playground.shared.SerdeFactory;
import kstreams.playground.shared.StreamApp;
import org.apache.kafka.clients.admin.NewTopic;
import org.apache.kafka.common.serialization.Serde;
import org.apache.kafka.common.serialization.Serdes;
import org.apache.kafka.common.serialization.Serdes.StringSerde;
import org.apache.kafka.streams.StreamsBuilder;
import org.apache.kafka.streams.StreamsConfig;
import org.apache.kafka.streams.errors.LogAndContinueExceptionHandler;
import org.apache.kafka.streams.kstream.Consumed;
import org.apache.kafka.streams.kstream.Named;
import org.apache.kafka.streams.kstream.Produced;
import org.apache.kafka.streams.kstream.Repartitioned;
import org.apache.kafka.streams.state.Stores;
import org.apache.kafka.streams.state.internals.ValueAndTimestampSerde;

public class App extends StreamApp {

    public static void main(String[] args) throws Exception {
        App streamApp = new App();
        AppContext.loadConfig(args);
        Properties extraProperties = new Properties();

//        extraProperties.setProperty(StreamsConfig.CACHE_MAX_BYTES_BUFFERING_CONFIG, "0");
//        extraProperties.setProperty(StreamsConfig.STATE_DIR_CONFIG, "/tmp/tweet-filter");
        extraProperties.setProperty(StreamsConfig.APPLICATION_ID_CONFIG, "uc-1-app");
        extraProperties.setProperty(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, StringSerde.class.getName());
        extraProperties.setProperty(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, SpecificAvroSerde.class.getName());
        extraProperties.setProperty(StreamsConfig.DEFAULT_DESERIALIZATION_EXCEPTION_HANDLER_CLASS_CONFIG,
            LogAndContinueExceptionHandler.class.getName());

        AppContext.getTopicManager()
            .create(Collections.singletonList(
            new NewTopic(Constant.TOPIC_USER_WITH_MULTIPLE_VIEWS, 6, (short) 3)));

        streamApp.run(extraProperties);
    }


    @Override
    protected void buildTopology(StreamsBuilder builder) {

        Serde<String> stringSerde = Serdes.String();
        SpecificAvroSerde<pageviews> pageviewsSerde = SerdeFactory.getAvroSerde();


        // This state store will hold a map of the key (userid) with a Value(pageid)+timestamp
        // so we can compute time differences
        builder.addStateStore(Stores.keyValueStoreBuilder(
            Stores.persistentKeyValueStore(Constant.PAGE_ID_TS_STORE),
            Serdes.String(),
            new ValueAndTimestampSerde<String>(stringSerde)
        ));

        builder
            .stream(Constant.TOPIC_INPUT, Consumed.with(stringSerde, pageviewsSerde))
            .peek((key, value) -> logger.debug("{} observed event ==>  {}", Constant.LOG_PREFIX, value))
            // the data has the `viewtime` as the key, we need the `userid` hence we select the new
            // key from the value
            .selectKey((key, value) -> value.getUserid())
            // Then we trigger the repartition explicitly
            .repartition(Repartitioned.as("user-id-repartition"))
            .process(() -> new KeyRepeatedInWindowProcessor(Duration.ofMinutes(5)),
                Named.as("key-repeated-in-window-processor"),
                Constant.PAGE_ID_TS_STORE)
            .to(Constant.TOPIC_USER_WITH_MULTIPLE_VIEWS, Produced.with(stringSerde, pageviewsSerde));
    }
}
